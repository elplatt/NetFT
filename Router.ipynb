{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from multiprocessing import Process, Queue\n",
    "import networkx as nx\n",
    "from networkx.algorithms.components import connected_components\n",
    "from networkx.algorithms.connectivity import node_connectivity\n",
    "from networkx.algorithms.centrality.betweenness import betweenness_centrality\n",
    "from networkx.algorithms.distance_measures import diameter\n",
    "from networkx.readwrite import json_graph\n",
    "import numpy as np\n",
    "import elp_networks as elpnet\n",
    "import elp_networks.algorithms as elpalg\n",
    "import logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rewire_f = 0.9\n",
    "#rewire_f = float(sys.argv[1])\n",
    "butterfly_m = 9\n",
    "num_conn_pairs = 150\n",
    "net_file = \"external/as20000102.csv\"\n",
    "out_file = \"stats.csv\"\n",
    "graph_file = \"rewired.json\"\n",
    "try:\n",
    "    job_id = os.environ[\"PBS_ARRAYID\"]\n",
    "except KeyError:\n",
    "    job_id = 0\n",
    "exp_name = \"router_targeted_\" + \"%02d\" % (int(round(rewire_f * 100)))\n",
    "exp_suffix = str(job_id)\n",
    "exp_ts = str(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(hash('''\n",
    "    Build a man a fire, and he'll be warm for a day.\n",
    "    Set a man on fire, and he'll be warm for the rest of his life.\n",
    "                                                â€“Terry Pratchett\n",
    "''' + exp_ts + str(job_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rewire_butterfly(g, fraction, butterfly_m):\n",
    "    m = butterfly_m\n",
    "    # Create butterfly and shuffle edges\n",
    "    butterfly = elpnet.Butterfly(m)\n",
    "    bf_nodes = list(butterfly.int_nodes())\n",
    "    bf_edges = set()\n",
    "    for bv in bf_nodes:\n",
    "        for bw in butterfly.int_neighbors(bv):\n",
    "            bf_edges.add(tuple(sorted([bv,bw])))\n",
    "    bf_edges = list(bf_edges)\n",
    "    random.shuffle(bf_edges)\n",
    "    num_bnodes = len(bf_nodes)\n",
    "    # Use highest-degree nodes to create router-butterfly map\n",
    "    rewire_nodes = [x[0] for x in sorted(dict(g.degree()).items(), key=lambda x: x[1], reverse=True)][:num_bnodes]\n",
    "    if False:\n",
    "        # Only sample nodes that can be completely rewired\n",
    "        # This list maps butterfly node labels to router node labels\n",
    "        rewire_nodes = random.sample([n for n in g.nodes() if len(list(g.neighbors(n))) >= 4], num_bnodes)\n",
    "    router_to_bf = dict([(r, b) for b, r in enumerate(rewire_nodes)])\n",
    "    router_edges = set()\n",
    "    for rv in rewire_nodes:\n",
    "        for rw in g.neighbors(rv):\n",
    "            if rw in rewire_nodes:\n",
    "                router_edges.add(tuple(sorted([rv, rw])))\n",
    "    router_edges = list(router_edges)\n",
    "    random.shuffle(router_edges)\n",
    "    to_rewire = int(math.floor(fraction * len(bf_edges)))\n",
    "    for i in range(to_rewire):\n",
    "        rv, rw = router_edges.pop()\n",
    "        g.remove_edge(rv, rw)\n",
    "        bv, bw = bf_edges.pop()\n",
    "        rv = rewire_nodes[bv]\n",
    "        rw = rewire_nodes[bw]\n",
    "        g.add_edge(rv, rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edge_list = []\n",
    "whitespace = re.compile(r\"\\w+\")\n",
    "nodes = set()\n",
    "with open(net_file, \"rb\") as f:\n",
    "    for row in f:\n",
    "        if row.startswith(\"#\"):\n",
    "            continue\n",
    "        source, target = re.split(r\"\\W+\", row.strip())\n",
    "        source = int(source.strip())\n",
    "        target = int(target.strip())\n",
    "        nodes.add(source)\n",
    "        nodes.add(target)\n",
    "        edge_list.append( (source,target) )\n",
    "node_count = len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_failure_work(g):\n",
    "    centralities = betweenness_centrality(g, normalized=False)\n",
    "    v, c = max(centralities.iteritems(), key=lambda x: x[1])\n",
    "    return v, c\n",
    "\n",
    "def failure_worker(graph_q, component_inq, connectivity0_inq, connectivity1_inq, connectivity2_inq, connectivity3_inq, failure_outq):\n",
    "    while True:\n",
    "        g = graph_q.get()\n",
    "        component_inq.put(g)\n",
    "        connectivity0_inq.put(g)\n",
    "        connectivity1_inq.put(g)\n",
    "        connectivity2_inq.put(g)\n",
    "        connectivity3_inq.put(g)\n",
    "        v, c = do_failure_work(g)\n",
    "        failure_outq.put((v,c))\n",
    "        if c > 0:\n",
    "            next_g = g.copy()\n",
    "            next_g.remove_node(v)\n",
    "            graph_q.put(next_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_component_work(g):\n",
    "    return list(connected_components(g))\n",
    "\n",
    "def component_worker(component_inq, diameter_inq, size_inq):\n",
    "    while True:\n",
    "        g = component_inq.get()\n",
    "        components = do_component_work(g)\n",
    "        diameter_inq.put( (components, g) )\n",
    "        size_inq.put(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_diameter_work(components, g):\n",
    "    giant_nodes = set(max(components, key=len))\n",
    "    giant_edges = []\n",
    "    for source, target in g.edges():\n",
    "        if source in giant_nodes and target in giant_nodes:\n",
    "            giant_edges.append( (source, target) )\n",
    "    giant = nx.Graph(giant_edges)\n",
    "    return diameter(giant)\n",
    "\n",
    "def diameter_worker(diameter_inq, diameter_outq):\n",
    "    while True:\n",
    "        components, g = diameter_inq.get()\n",
    "        diameter = do_diameter_work(components, g)\n",
    "        diameter_outq.put(diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_size_work(components):\n",
    "    giant_nodes = max(components, key=len)\n",
    "    total = sum([len(x) for x in components])\n",
    "    try:\n",
    "        result = float(total - len(giant_nodes)) / float(len(components) - 1)\n",
    "    except ZeroDivisionError:\n",
    "        result = 0\n",
    "    return result\n",
    "\n",
    "def size_worker(size_inq, size_outq):\n",
    "    while True:\n",
    "        components = size_inq.get()\n",
    "        size_outq.put(do_size_work(components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_pairs(nodes, num):\n",
    "    # Sample sources and targets\n",
    "    nodes = list(nodes)\n",
    "    sources = random.sample(nodes, num)\n",
    "    targets = random.sample(nodes, num)\n",
    "    # Replace self loops\n",
    "    for i in range(num - 1):\n",
    "        if sources[i] == targets[i]:\n",
    "            sources[i], sources[-1] = sources[-1], sources[i]\n",
    "    if sources[-1] == targets[-1]:\n",
    "        sources[-1] = random.choice(list(set(nodes) - set(sources)))\n",
    "    pairs = zip(sources, targets)\n",
    "    return pairs\n",
    "    \n",
    "def expand(g, source, radius):\n",
    "    if radius == 0:\n",
    "        return set(), set()\n",
    "    # Get all nodes within radius\n",
    "    neighbors = set(nx.ego_graph(g, source, radius=radius).nodes())\n",
    "    neighbors.remove(source)\n",
    "    # Keep track of the boundary and remove nodes within radius\n",
    "    boundary = set()\n",
    "    for v in neighbors:\n",
    "        boundary |= set(nx.neighbors(g, v))\n",
    "    # Remove source (unless boundary is empty)\n",
    "    boundary.discard(source)\n",
    "    return neighbors, boundary\n",
    "        \n",
    "def do_connectivity_work(g, radius):\n",
    "    pairs = sample_pairs(g.nodes(), num_conn_pairs)\n",
    "    # Calculate connectivity for sampled pairs\n",
    "    connectivities = []\n",
    "    for source, target in pairs:\n",
    "        s_neighbors, s_boundary = expand(g, source, radius)\n",
    "        t_neighbors, t_boundary = expand(g, target, radius)\n",
    "        expanded = g.copy()\n",
    "        # Get list of all neighbors, remaining s/t boundaries\n",
    "        neighbors = (t_neighbors | s_neighbors) - set([target]) - set([source])\n",
    "        s_boundary -= neighbors\n",
    "        t_boundary -= neighbors\n",
    "        # If neighborhoods overlap, combine\n",
    "        common = s_neighbors & t_neighbors\n",
    "        if len(common) > 0:\n",
    "            boundary = (s_boundary | t_boundary) - set([target]) - set([source])\n",
    "            s_boundary = boundary\n",
    "            t_boundary = boundary\n",
    "            target = source\n",
    "        # Remove neighbors and create edges to boundary\n",
    "        for v in s_boundary:\n",
    "            expanded.add_edge(source, v)\n",
    "        for v in t_boundary:\n",
    "            expanded.add_edge(target, v)\n",
    "        for v in neighbors:\n",
    "            expanded.remove_node(v)\n",
    "        try:\n",
    "            c = node_connectivity(expanded, source, target)\n",
    "        except nx.NetworkXError:\n",
    "            print source, target\n",
    "            print s_boundary\n",
    "            print t_boundary\n",
    "            print neighbors\n",
    "            raise\n",
    "        connectivities.append(c)\n",
    "    # Calculate statistics\n",
    "    mean = np.mean(connectivities)\n",
    "    std = np.std(connectivities, ddof=1)\n",
    "    se = mean / np.sqrt(len(connectivities))\n",
    "    return (mean, se)\n",
    "\n",
    "def connectivity_worker(connectivity_inq, connectivity_outq, radius):\n",
    "    while True:\n",
    "        g = connectivity_inq.get()\n",
    "        data = do_connectivity_work(g, radius)\n",
    "        connectivity_outq.put(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph_q = Queue(maxsize=4)\n",
    "failure_outq = Queue()\n",
    "component_inq = Queue(maxsize=4)\n",
    "diameter_inq = Queue(maxsize=4)\n",
    "diameter_outq = Queue()\n",
    "size_inq = Queue(maxsize=4)\n",
    "size_outq = Queue()\n",
    "connectivity0_inq = Queue(maxsize=4)\n",
    "connectivity0_outq = Queue()\n",
    "connectivity1_inq = Queue(maxsize=4)\n",
    "connectivity1_outq = Queue()\n",
    "connectivity2_inq = Queue(maxsize=4)\n",
    "connectivity2_outq = Queue()\n",
    "connectivity3_inq = Queue(maxsize=4)\n",
    "connectivity3_outq = Queue()\n",
    "\n",
    "exp = logbook.Experiment(exp_name, suffix=exp_suffix)\n",
    "log = exp.get_logger()\n",
    "\n",
    "log.info(\"Rewiring graph\")\n",
    "g = nx.Graph(edge_list)\n",
    "rewire_butterfly(g, rewire_f, butterfly_m)\n",
    "graph_q.put(g)\n",
    "\n",
    "log.info(\"Starting workers\")\n",
    "workers = []\n",
    "workers.append(Process(target=failure_worker, args=(graph_q, component_inq, connectivity0_inq, connectivity1_inq, connectivity2_inq, connectivity3_inq, failure_outq)))\n",
    "workers.append(Process(target=component_worker, args=(component_inq, diameter_inq, size_inq)))\n",
    "workers.append(Process(target=diameter_worker, args=(diameter_inq, diameter_outq)))\n",
    "workers.append(Process(target=size_worker, args=(size_inq, size_outq)))\n",
    "workers.append(Process(target=connectivity_worker, args=(connectivity0_inq, connectivity0_outq, 0)))\n",
    "workers.append(Process(target=connectivity_worker, args=(connectivity1_inq, connectivity1_outq, 1)))\n",
    "workers.append(Process(target=connectivity_worker, args=(connectivity2_inq, connectivity2_outq, 2)))\n",
    "workers.append(Process(target=connectivity_worker, args=(connectivity3_inq, connectivity3_outq, 3)))\n",
    "\n",
    "for w in workers:\n",
    "    w.daemon = True\n",
    "    w.start()\n",
    "    \n",
    "with open(exp.get_filename(out_file), \"wb\") as out:\n",
    "    log.info(\"Starting\")\n",
    "    node_betweenness = {}\n",
    "    finished = 0\n",
    "    out.write(\"removed,diameter,size,node_conn0_mean,node_conn0_se,node_conn1_mean,node_conn1_se,node_conn2_mean,node_conn2_se,node_conn3_mean,node_conn3_se,node_conn_pairs,failed,high_betweenness,node_count,rewire_f,butterfly_m,failure_type\\n\")\n",
    "    while finished < node_count:\n",
    "        log.info(\"Iteration {}\".format(finished))\n",
    "        log.info(\"  Finding betweenness\")\n",
    "        label, centrality = failure_outq.get()\n",
    "        node_betweenness[label] = centrality\n",
    "        log.info(\"  Finding diameter\")\n",
    "        diameter = diameter_outq.get()\n",
    "        log.info(\"  Finding size\")\n",
    "        size = size_outq.get()\n",
    "        log.info(\"  Finding 0-connectivity\")\n",
    "        node_conn0_mean, node_conn0_se = connectivity0_outq.get()\n",
    "        log.info(\"  Finding 1-connectivity\")\n",
    "        node_conn1_mean, node_conn1_se = connectivity1_outq.get()\n",
    "        log.info(\"  Finding 2-connectivity\")\n",
    "        node_conn2_mean, node_conn2_se = connectivity2_outq.get()\n",
    "        log.info(\"  Finding 3-connectivity\")\n",
    "        node_conn3_mean, node_conn3_se = connectivity3_outq.get()\n",
    "        node_conn0_mean, node_conn0_se = 0,0\n",
    "        node_conn1_mean, node_conn1_se = 0,0\n",
    "        node_conn2_mean, node_conn2_se = 0,0\n",
    "        node_conn3_mean, node_conn3_se = 0,0\n",
    "        log.info(\"  Writing row\")\n",
    "        row = [finished, diameter, size, node_conn0_mean, node_conn0_se, node_conn1_mean, node_conn1_se, node_conn2_mean, node_conn2_se, node_conn3_mean, node_conn3_se, num_conn_pairs, label, centrality, node_count, rewire_f, butterfly_m,\"targeted\"]\n",
    "        out.write(\",\".join([str(d) for d in row]) + \"\\n\")\n",
    "        out.flush()\n",
    "        finished += 1\n",
    "        if centrality == 0:\n",
    "            break\n",
    "log.info(\"Finished simulation, writing graph\")\n",
    "with open(exp.get_filename(graph_file), \"wb\") as f:\n",
    "    nx.set_node_attributes(g, 'betweenness_recalc', node_betweenness)\n",
    "    data = json_graph.node_link_data(g)\n",
    "    f.write(json.dumps(data))\n",
    "log.info(\"Finished successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
